<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Hello Friend NG</title>
        <link>localhost/posts/</link>
        <description>Recent content in Posts on Hello Friend NG</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
        <lastBuildDate>Mon, 22 Feb 2021 20:25:19 -0800</lastBuildDate>
        <atom:link href="localhost/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Making Sense of Your Data With Python</title>
            <link>localhost/posts/python-data-analysis/</link>
            <pubDate>Mon, 22 Feb 2021 20:25:19 -0800</pubDate>
            
            <guid>localhost/posts/python-data-analysis/</guid>
            <description>About  Communication is a massive part of any good security program. Being able to demonstrate successes, failures, and areas of improvement for organizational security posture to the executive level is critical to receiving buy-in and resources from your business to mitigate risk in your environment effectively. If the business does not see the need for spending more time and money on security, they likely will turn their attention elsewhere.</description>
            <content type="html"><![CDATA[<h2 id="about">About</h2>
<hr>
<p>Communication is a massive part of any good security program. Being able to demonstrate successes, failures, and areas of improvement for organizational security posture to the executive level is critical to receiving buy-in and resources from your business to mitigate risk in your environment effectively. If the business does not see the need for spending more time and money on security, they likely will turn their attention elsewhere.</p>
<p>One of the best methods for demonstrating security posture is to provide metrics from existing security controls, but this often easier said than done. Many security tools will allow you to visualize trends within themselves, and many will allow you to export data to spreadsheets, or provide APIs to pull data.</p>
<hr>
<h2 id="intro-to-pandas">Intro to Pandas</h2>
<p>Pandas is a great tool for programmatically handling spreadsheets with Python. Pandas can easily convert formats like CSV, Excel, and Python Dictionaries to Pandas <em>DataFrames</em>. A Pandas DataFrame is a data structure that organizes data into rows and columns, and provides the flexibility to easily manipulate formatted data for analysis</p>
<h3 id="working-with-dataframes">Working with DataFrames</h3>
<p><strong>This section assumes that you have some knowledge of Python 3.x with topics like lists, dictionaries, and conditional statements.</strong></p>
<ol>
<li>
<p>Install Pandas</p>
<p>Use <code>pip install pandas</code> (or <code>pip3 install pandas</code> if Pip for Python 3.x is not set as your default Pip install)</p>
</li>
<li>
<p>Create your file and import Pandas
Create a file, name it something like <code>analytics.py</code> or <code>csv-parsing.py</code>. Import Pandas by adding this line of code to the top of your file</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> pandas
</code></pre></div><p>``</p>
</li>
<li>
<p>Create or upload your CSV File
&hellip;</p>
</li>
</ol>
]]></content>
        </item>
        
        <item>
            <title></title>
            <link>localhost/posts/kubernetes-basics/</link>
            <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
            
            <guid>localhost/posts/kubernetes-basics/</guid>
            <description>Baby&amp;rsquo;s First Kubernetes What is it?  Kubernetes (K8s) is an open-source container orchestration tool for managing applications on container runtimes like Docker. K8s uses a collection of controller services hosted on a master server(s) to manage worker servers in a server cluster. The application code is held on the worker servers, and the master server controls when, what, and how containers are built on the worker servers.  High-level K8s Architecture  Kubernetes Documentation at: https://kubernetes.</description>
            <content type="html"><![CDATA[<h1 id="babys-first-kubernetes">Baby&rsquo;s First Kubernetes</h1>
<h2 id="what-is-it">What is it?</h2>
<ul>
<li>Kubernetes (K8s) is an open-source container orchestration tool for managing applications on container runtimes like Docker.</li>
<li>K8s uses a collection of controller services hosted on a <strong>master</strong> server(s) to manage <strong>worker</strong> servers in a server cluster. The application code is held on the worker servers, and the master server controls when, what, and how containers are built on the worker servers.</li>
</ul>
<h3 id="high-level-k8s-architecture">High-level K8s Architecture</h3>
<p><img src="assets/simple_kubernetes.png" alt=""></p>
<ul>
<li>Kubernetes Documentation at: <a href="https://kubernetes.io/docs/home/">https://kubernetes.io/docs/home/</a></li>
<li>Docker Documentation at: <a href="https://docs.docker.com/">https://docs.docker.com/</a></li>
</ul>
<hr>
<h2 id="why-use-it">Why use it?</h2>
<ul>
<li>K8s is a tool that allows you to centrally manage coontainer image deployment and updates, define resource usage standards, monitor the health of an application, and maintain control over an environment at-scale when running services on containers.</li>
<li>If configured correctly, provides high fault-tolerance for your container app.</li>
<li>it is best use where containers are being used for large apps with mutliple microservices requiring High Availibility and redundancy.</li>
</ul>
<hr>
<h2 id="alternatives">Alternatives</h2>
<ul>
<li>K8s is NOT the only solution for managing containers at scale, but it is the most popular. Other solutions include Amazon Elastic Container Service (ECS), Docker Swarm, and OpenShift.</li>
<li>For containerized small apps on a single server,a more straight-foward service with less focus on distributed services like Docker Compose is the best way to go.</li>
<li>Amazon Elastic Kubernetes Service (EKS) and Google Kubernetes Engine (GKE) are managed solutions that allow teams to delegate the managment of the underlying operating system and hardware to a cloud provider.</li>
</ul>
<hr>
<h2 id="a-few-key-sysopsdeployment-concepts">A few key SysOps/Deployment Concepts</h2>
<h3 id="high-availibility">High Availibility</h3>
<ul>
<li>
<p><strong>High Availibility (HA)</strong> is the concept of making your application/service fault-tolerant and redundant, as to prevent downtime in the case of an incident. Examples of incidents that High Availibility configurations attempt to solve for are:</p>
<ul>
<li>A server is overloaded with requests and users are unable to reach the service.</li>
<li>A database experiances temporary IO suspension due to a scheduled backup.</li>
<li>A natural disaster knocks out power in a datacenter, leaving your servers unresponsive for a period of time.</li>
<li>A bug causes an application to crash unexpectedly.</li>
</ul>
</li>
<li>
<p>Common solutions for providing <strong>High Availibility</strong> include:</p>
<ul>
<li>hosting servers in multiple data centers across multiple regions (ideally, at least 3).</li>
<li>backing up data to storage that is isolated from the data store being backed-up.</li>
<li>Automate health-checks to fail-over between servers if a server is experiancing issues</li>
<li>Disaster planning, have back-up servers on standby</li>
</ul>
</li>
</ul>
<h2 id="scalability">Scalability</h2>
<ul>
<li>Providing <strong>Scalability</strong> in the context of a application is the process of building a system to effeciently adjust for variance in compute or traffic load. When the amount of people shopping for electric drumkits and gamer chairs doubles on cyber monday, an online store and its components should be able to adjust on-the-fly to handle the load</li>
<li>To allow your application/service to be scalable, you can:
<ul>
<li>Monitor the health/resource usage of application servers and write code to create new virtual machines to meet new requirements. Have your automation delete these new virtual machines when the load is back to normal.</li>
<li>Use one of the many solutions provided by cloud providers, like AWS EC2 AutoScaling, to create new cloud servers to match the compute capacity needed, delete these servers when the load decreases.</li>
<li>Use Load Balancers to direct traffic to instances using round-robin or other traffic direction method to allow traffic to reach new servers on-the-fly</li>
</ul>
</li>
<li>Applications can scale <strong>horizontally</strong> or <strong>vertically</strong>
<ul>
<li>Horizontal scaling: Create new instances of the application server of the same/similar size. Ex: a server uses 90% of its CPU capacity, a new virtual server is created with the same CPU capacity and requests are load-balanced between the two servers.</li>
<li>Vertical scaling: Create a larger version of the application server. Ex: a server uses 90% of its CPU capacity, a new instance is created with a higher-end CPU and traffic is redirected.</li>
</ul>
</li>
</ul>
<h3 id="okay-finally-back-to-kubernetes">Okay, finally back to Kubernetes</h3>
<h2 id="kubernetes-components">Kubernetes Components</h2>
<h3 id="key-terms">Key Terms:</h3>
<ul>
<li><strong>Node:</strong> A single virtual/physical server/instance</li>
<li><strong>Control Plane</strong>: the server(s)/instance(s) that command and control the worker nodes</li>
<li><strong>Pod:</strong> One or more containers on a node, smallest component in K8s</li>
<li><strong>Load Balancer:</strong> A physical or virtual networking component that directs traffic between nodes.</li>
</ul>
<h3 id="nodes">Nodes</h3>
<ul>
<li>Nodes are individual physical/virtual servers that contain a number of components to send/recieve instructions from the master node (see <strong>Control Plane</strong> for details) and host the containers running your service. Node components include:
<ul>
<li><strong>Pod:</strong> the smallest unit in the K8s architecture, pods contain one or more containers that are tightly coupled to serve a single function. Multiple container pods might be implemented where a seperate container is acting as a networking proxy, acting as a helper or sidecar container to handle logging, monitoring,</li>
<li><strong>kubelet:</strong> the K8s agent running on each node that communicates back to the control plane</li>
<li><strong>kube-proxy</strong>: A network proxy that maintains network rules permitting traffic from the node to other parts of the cluster, or outside of the cluster.</li>
</ul>
</li>
</ul>
<h3 id="control-plane">Control Plane</h3>
<ul>
<li>The Control Plane is a collection of cluster managment services that run across multiple servers. These services track the health of worker nodes, keep inventory of what containers are deployed and where, track and update what container images are being used, and provide an API interface for administrators to manage the cluster.</li>
<li>Some Control Plane Components Are:
<ul>
<li><strong>API Server:</strong>
<ul>
<li>Exposes the K8s API, usually with the kube-apiserver implementation. This implementation scales to match load needs by deploying new instances to handle API requests (horizontal scaling)</li>
</ul>
</li>
<li><strong>Cloud Controller Manager (optional if running locally):</strong>
<ul>
<li>Controls the cloud infrastructure for your specific cloud provider&rsquo;s infrastructure.</li>
<li>Service Controller: Creates load balancers</li>
<li>Route Controller: manages routes within the cloud provider&rsquo;s infrastructure</li>
<li>Node controller: Checks to see if an unresponsive node was terminated by the cloud provider</li>
</ul>
</li>
<li><strong>Controller Manager:</strong> kube-controller-manager runs each of the controller processes as a single binary. These controller processes include:
<ul>
<li>Node controller: Checks on the status of nodes and respond when a node goes down</li>
<li>Replication controller: maintains the correct number of pods.</li>
<li>Endpoints controller: joins services to pods by populating an Endpoints object</li>
<li>Service accounta nd Token controllers; Creates the default accounts and API access tokens for new namespaces</li>
</ul>
</li>
<li><strong>Scheduler:</strong> kube-scheduler watches for newly created pods that have not been assigned a node, and selects a node for them to run on based on resource requiremetnts, hardware/software policy constraints, label-based eligibility (affinity and anti-affinity), deadlines and workload interference.</li>
<li><strong>etcd:</strong> A highly-availible (distributed across servers) key-value store for all persistent cluster data. Periodic back-ups are recommended here.</li>
</ul>
</li>
</ul>
<p><img src="assets/k8s_diagram.png" alt=""></p>
<h2 id="in-practice">In Practice</h2>
<ul>
<li>Kubernetes at-scale can require a significant amount of engineering resources and can become complex as an application grows and the number of microservices increases. Running self-managed K8s in production should be restricted to companies with experienced staff and the people-power to manage it securely.</li>
<li>If a team runs a service or application running across multiple cloud providers, A service like Amazon&rsquo;s Elastic Kubernetes Service (EKS) may be a better alternative. EKS provides high availibility and redundancy by default, with three master nodes across three availibility zones (data centers) by default, but can still be controlled via the K8s api using kube-ctl.</li>
<li>If a team runs an AWS-native application, a managed service like Amazon ECS on EC2 or Fargate can be employed to more easily integrate with AWS-native services.</li>
</ul>
]]></content>
        </item>
        
    </channel>
</rss>
